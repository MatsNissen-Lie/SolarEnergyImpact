{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from pipeline import DataPipeline\n",
    "pipe = DataPipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "referance_buildings = pipe.get_reference_buildings_import_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "referance_buildings\n",
    "# select these columns from the data\n",
    "# value\ttimestamp temperature area wind_speed\twind_direction\tcloud_fraction\tprecipitation\n",
    "\n",
    "data_for_model = referance_buildings[['value', 'timestamp', 'temperature', 'area', 'wind_speed', 'wind_direction', 'cloud_fraction', 'precipitation']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241016_094809\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       12.94 GB / 32.00 GB (40.4%)\n",
      "Disk Space Avail:   654.40 GB / 926.35 GB (70.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241016_094809\"\n",
      "Train Data Rows:    24696\n",
      "Train Data Columns: 6\n",
      "Label Column:       value\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (93.4, 0.0, 34.83129, 11.68569)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13229.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.13 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['temperature', 'wind_speed', 'wind_direction', 'cloud_fraction', 'precipitation']\n",
      "\t\t('int', [])   : 1 | ['area']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['temperature', 'wind_speed', 'wind_direction', 'cloud_fraction', 'precipitation']\n",
      "\t\t('int', [])   : 1 | ['area']\n",
      "\t0.0s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.13 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22226, Val Rows: 2470\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-7.1779\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248808\n",
      "246960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-7.1041\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 7.21816\n",
      "[2000]\tvalid_set's l1: 7.18891\n",
      "[3000]\tvalid_set's l1: 7.17437\n",
      "[4000]\tvalid_set's l1: 7.17716\n",
      "[5000]\tvalid_set's l1: 7.18153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-7.1714\t = Validation score   (-mean_absolute_error)\n",
      "\t41.38s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 6.74441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.7366\t = Validation score   (-mean_absolute_error)\n",
      "\t9.31s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-6.5242\t = Validation score   (-mean_absolute_error)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-6.7183\t = Validation score   (-mean_absolute_error)\n",
      "\t79.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-6.4912\t = Validation score   (-mean_absolute_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ag/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t-6.9301\t = Validation score   (-mean_absolute_error)\n",
      "\t21.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-6.7673\t = Validation score   (-mean_absolute_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t-6.4878\t = Validation score   (-mean_absolute_error)\n",
      "\t184.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 6.69748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.6921\t = Validation score   (-mean_absolute_error)\n",
      "\t12.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.619, 'ExtraTreesMSE': 0.238, 'RandomForestMSE': 0.143}\n",
      "\t-6.3694\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 357.33s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 20126.6 rows/s (2470 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241016_094809\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming you have a DataFrame called 'referance_buildings'\n",
    "print(data_for_model.size)\n",
    "data_for_model = data_for_model.dropna()  # Drop missing values if any\n",
    "print(data_for_model.size)\n",
    "\n",
    "# Convert timestamp column to datetime and use numerical features\n",
    "data_for_model['timestamp'] = pd.to_datetime(data_for_model['timestamp'])\n",
    "# data_for_model['hour'] = data_for_model['timestamp'].dt.hour\n",
    "# data_for_model['dayofweek'] = data_for_model['timestamp'].dt.dayofweek\n",
    "\n",
    "# Drop timestamp column as it is not directly usable by the model\n",
    "data_for_model = data_for_model.drop(columns=['timestamp'])\n",
    "\n",
    "# Define the target column and features\n",
    "target = 'value'\n",
    "\n",
    "# Split into train and test\n",
    "train_data = data_for_model.sample(frac=0.8, random_state=42)\n",
    "test_data = data_for_model.drop(train_data.index)\n",
    "\n",
    "# Train the model using AutoGluon\n",
    "predictor = TabularPredictor(label=target, eval_metric='mean_absolute_error').fit(\n",
    "    train_data, \n",
    "    # presets='best_quality'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 6 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Performance:\n",
      "{'mean_absolute_error': -6.451102537680954, 'root_mean_squared_error': -8.755899317452531, 'mean_squared_error': -76.6657728573657, 'r2': 0.4564347759561109, 'pearsonr': 0.6812870538718883, 'median_absolute_error': -4.859660873413086}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t22.18s\t= Expected runtime (4.44s per shuffle set)\n",
      "\t8.95s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "                importance    stddev       p_value  n  p99_high   p99_low\n",
      "area              4.005987  0.089819  3.030537e-08  5  4.190925  3.821049\n",
      "temperature       2.447230  0.053404  2.719677e-08  5  2.557190  2.337269\n",
      "wind_direction    0.698313  0.023069  1.427140e-07  5  0.745813  0.650814\n",
      "wind_speed        0.637683  0.032960  8.534659e-07  5  0.705549  0.569817\n",
      "cloud_fraction    0.380224  0.026137  2.662699e-06  5  0.434041  0.326407\n",
      "precipitation     0.236724  0.024285  1.310609e-05  5  0.286726  0.186721\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "performance = predictor.evaluate(test_data)\n",
    "\n",
    "print(\"Evaluation Performance:\")\n",
    "print(performance)  # This will show various metrics such as R^2, RMSE, etc.\n",
    "\n",
    "# To see feature importance\n",
    "global_importance = predictor.feature_importance(test_data)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(global_importance)  # Shows which features had the most impact on model predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
