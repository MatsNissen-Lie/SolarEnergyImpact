{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matsalexander/Desktop/SolarEnergyImpact\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from pathlib import Path\n",
    "import sys\n",
    "root = Path().resolve().absolute().parent.parent\n",
    "print(root)\n",
    "sys.path.append(str(root))\n",
    "\n",
    "from src.pipeline import Pipeline, BuilingIdsEnum\n",
    "pipe = Pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_a = pipe.get_data(BuilingIdsEnum.A)\n",
    "building_b = pipe.get_data(BuilingIdsEnum.B)\n",
    "building_c = pipe.get_data(BuilingIdsEnum.C)\n",
    "combined_df = pd.concat([building_a, building_b, building_c])\n",
    "# Perform the train-test split with stratification based on 'building_id'\n",
    "train_data, test_data = train_test_split(\n",
    "    combined_df,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=combined_df['building']\n",
    ")\n",
    "\n",
    "# select features\n",
    "features = [\"timestamp\", \"area\", \"temperature\", \"wind_speed\", \"cloud_fraction\", \"precipitation\"]\n",
    "target = \"value_import\"\n",
    "\n",
    "train_data = train_data[features + [target]]\n",
    "test_data = test_data[features + [target]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241109_030847\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       14.70 GB / 32.00 GB (45.9%)\n",
      "Disk Space Avail:   622.90 GB / 926.35 GB (67.2%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241109_030847\"\n",
      "Train Data Rows:    24880\n",
      "Train Data Columns: 6\n",
      "Label Column:       value_import\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (93.4, 0.0, 34.86557, 11.74666)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15042.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) : 1 | ['timestamp']\n",
      "\t\t('float', [])    : 4 | ['temperature', 'wind_speed', 'cloud_fraction', 'precipitation']\n",
      "\t\t('int', [])      : 1 | ['area']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 4 | ['temperature', 'wind_speed', 'cloud_fraction', 'precipitation']\n",
      "\t\t('int', [])                  : 1 | ['area']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['timestamp', 'timestamp.year', 'timestamp.month', 'timestamp.day', 'timestamp.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t6 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.90 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22392, Val Rows: 2488\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 6.06772\n",
      "[2000]\tvalid_set's l1: 5.7793\n",
      "[3000]\tvalid_set's l1: 5.59873\n",
      "[4000]\tvalid_set's l1: 5.48377\n",
      "[5000]\tvalid_set's l1: 5.40339\n",
      "[6000]\tvalid_set's l1: 5.33925\n",
      "[7000]\tvalid_set's l1: 5.29278\n",
      "[8000]\tvalid_set's l1: 5.24658\n",
      "[9000]\tvalid_set's l1: 5.20613\n",
      "[10000]\tvalid_set's l1: 5.18081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.1808\t = Validation score   (-mean_absolute_error)\n",
      "\t43.01s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 4.5667\n",
      "[2000]\tvalid_set's l1: 4.4089\n",
      "[3000]\tvalid_set's l1: 4.30856\n",
      "[4000]\tvalid_set's l1: 4.25958\n",
      "[5000]\tvalid_set's l1: 4.23767\n",
      "[6000]\tvalid_set's l1: 4.22371\n",
      "[7000]\tvalid_set's l1: 4.21315\n",
      "[8000]\tvalid_set's l1: 4.20854\n",
      "[9000]\tvalid_set's l1: 4.20906\n",
      "[10000]\tvalid_set's l1: 4.20779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.2056\t = Validation score   (-mean_absolute_error)\n",
      "\t94.19s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-3.5728\t = Validation score   (-mean_absolute_error)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n"
     ]
    }
   ],
   "source": [
    "# Train the model using AutoGluon\n",
    "predictor = TabularPredictor(label=target, eval_metric='mean_absolute_error').fit(\n",
    "    train_data, \n",
    "    # presets='best_quality',\n",
    "    presets=\"medium_quality_faster_train\",\n",
    "    excluded_model_types=['KNN']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 3 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Performance:\n",
      "{'mean_absolute_error': -3.1217798479004197, 'root_mean_squared_error': -4.916806183789267, 'mean_squared_error': -24.174983048948373, 'r2': 0.8285978268071899, 'pearsonr': 0.9103643086413618, 'median_absolute_error': -1.762607803344725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t194.55s\t= Expected runtime (38.91s per shuffle set)\n",
      "\t162.11s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "             importance    stddev       p_value  n  p99_high   p99_low\n",
      "timestamp      5.904354  0.120787  2.100541e-08  5  6.153056  5.655651\n",
      "area           5.713944  0.122575  2.539637e-08  5  5.966327  5.461561\n",
      "temperature    5.251591  0.101069  1.645395e-08  5  5.459692  5.043489\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "performance = predictor.evaluate(test_data)\n",
    "# best model: ag-20241022_161331\n",
    "\n",
    "print(\"Evaluation Performance:\")\n",
    "print(performance)  # This will show various metrics such as R^2, RMSE, etc.\n",
    "\n",
    "# To see feature importance\n",
    "global_importance = predictor.feature_importance(test_data)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(global_importance)  # Shows which features had the most impact on model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-01 01:00:00</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-07-01 02:00:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-07-01 03:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-01 04:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54451</th>\n",
       "      <td>2024-09-04 19:00:00</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54456</th>\n",
       "      <td>2024-09-04 20:00:00</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54462</th>\n",
       "      <td>2024-09-04 21:00:00</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54468</th>\n",
       "      <td>2024-09-04 22:00:00</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54475</th>\n",
       "      <td>2024-09-04 23:00:00</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10343 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  temperature  area\n",
       "4     2023-07-01 00:00:00         13.6  1199\n",
       "8     2023-07-01 01:00:00         13.2  1199\n",
       "16    2023-07-01 02:00:00         12.3  1199\n",
       "20    2023-07-01 03:00:00         11.9  1199\n",
       "29    2023-07-01 04:00:00         11.9  1199\n",
       "...                   ...          ...   ...\n",
       "54451 2024-09-04 19:00:00         17.5  1199\n",
       "54456 2024-09-04 20:00:00         17.5  1199\n",
       "54462 2024-09-04 21:00:00         17.5  1199\n",
       "54468 2024-09-04 22:00:00         17.5  1199\n",
       "54475 2024-09-04 23:00:00         17.4  1199\n",
       "\n",
       "[10343 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model location => AutogluonModels/ag-20241016_095906\n",
    "main_building = pipe.get_data(BuilingIdsEnum.MAIN)\n",
    "\n",
    "data_predict = main_building[features]\n",
    "data_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciton1 = predictor.predict(data_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicitons as a csv in data folder from root.\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "prediciton1_df = pd.DataFrame(prediciton1)\n",
    "my_path = Path().resolve().parent / 'data' / 'prediction_drita.csv'\n",
    "prediciton1_df.to_csv(my_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
